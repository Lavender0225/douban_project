{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 豆瓣评分的预测\n",
    "\n",
    "在这个项目中，我们要预测一部电影的评分，这个问题实际上就是一个分类问题。给定的输入为一段文本，输出为具体的评分。 在这个项目中，我们需要做：\n",
    "- 文本的预处理，如停用词的过滤，低频词的过滤，特殊符号的过滤等\n",
    "- 文本转化成向量，将使用三种方式，分别为tf-idf, word2vec以及BERT向量。 \n",
    "- 训练逻辑回归和朴素贝叶斯模型，并做交叉验证\n",
    "- 评估模型的准确率\n",
    "\n",
    "在具体标记为``TODO``的部分填写相应的代码。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入数据处理的基础包\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#导入用于计数的包\n",
    "from collections import Counter\n",
    "\n",
    "#导入tf-idf相关的包\n",
    "from sklearn.feature_extraction.text import TfidfTransformer    \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#导入模型评估的包\n",
    "from sklearn import metrics\n",
    "\n",
    "#导入与word2vec相关的包\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#导入与bert embedding相关的包，关于mxnet包下载的注意事项参考实验手册\n",
    "from bert_embedding import BertEmbedding\n",
    "import mxnet\n",
    "\n",
    "#包tqdm是用来对可迭代对象执行时生成一个进度条用以监视程序运行过程\n",
    "from tqdm import tqdm\n",
    "\n",
    "#导入其他一些功能包\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 读取数据并做文本的处理\n",
    "你需要完成以下几步操作：\n",
    "- 去掉无用的字符如！&，可自行定义\n",
    "- 中文分词\n",
    "- 去掉低频词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Movie_Name_EN</th>\n",
       "      <th>Movie_Name_CN</th>\n",
       "      <th>Crawl_Date</th>\n",
       "      <th>Number</th>\n",
       "      <th>Username</th>\n",
       "      <th>Date</th>\n",
       "      <th>Star</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>然潘</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>3</td>\n",
       "      <td>连奥创都知道整容要去韩国。</td>\n",
       "      <td>2404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>11</td>\n",
       "      <td>影志</td>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>4</td>\n",
       "      <td>“一个没有黑暗面的人不值得信任。” 第二部剥去冗长的铺垫，开场即高潮、一直到结束，会有人觉...</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>21</td>\n",
       "      <td>随时流感</td>\n",
       "      <td>2015-04-28</td>\n",
       "      <td>2</td>\n",
       "      <td>奥创弱爆了弱爆了弱爆了啊！！！！！！</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>31</td>\n",
       "      <td>乌鸦火堂</td>\n",
       "      <td>2015-05-08</td>\n",
       "      <td>4</td>\n",
       "      <td>与第一集不同，承上启下，阴郁严肃，但也不会不好看啊，除非本来就不喜欢漫威电影。场面更加宏大...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>Avengers Age of Ultron</td>\n",
       "      <td>复仇者联盟2</td>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>41</td>\n",
       "      <td>办公室甜心</td>\n",
       "      <td>2015-05-10</td>\n",
       "      <td>5</td>\n",
       "      <td>看毕，我激动地对友人说，等等奥创要来毁灭台北怎么办厚，她拍了拍我肩膀，没事，反正你买了两份...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID           Movie_Name_EN Movie_Name_CN  Crawl_Date  Number Username  \\\n",
       "0   0  Avengers Age of Ultron        复仇者联盟2  2017-01-22       1       然潘   \n",
       "1  10  Avengers Age of Ultron        复仇者联盟2  2017-01-22      11       影志   \n",
       "2  20  Avengers Age of Ultron        复仇者联盟2  2017-01-22      21     随时流感   \n",
       "3  30  Avengers Age of Ultron        复仇者联盟2  2017-01-22      31     乌鸦火堂   \n",
       "4  40  Avengers Age of Ultron        复仇者联盟2  2017-01-22      41    办公室甜心   \n",
       "\n",
       "         Date  Star                                            Comment  Like  \n",
       "0  2015-05-13     3                                      连奥创都知道整容要去韩国。  2404  \n",
       "1  2015-04-30     4   “一个没有黑暗面的人不值得信任。” 第二部剥去冗长的铺垫，开场即高潮、一直到结束，会有人觉...   381  \n",
       "2  2015-04-28     2                                 奥创弱爆了弱爆了弱爆了啊！！！！！！   120  \n",
       "3  2015-05-08     4   与第一集不同，承上启下，阴郁严肃，但也不会不好看啊，除非本来就不喜欢漫威电影。场面更加宏大...    30  \n",
       "4  2015-05-10     5   看毕，我激动地对友人说，等等奥创要来毁灭台北怎么办厚，她拍了拍我肩膀，没事，反正你买了两份...    16  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取数据\n",
    "data = pd.read_csv('data/DMSC.csv')\n",
    "#观察数据格式\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 212506 entries, 0 to 212505\n",
      "Data columns (total 10 columns):\n",
      "ID               212506 non-null int64\n",
      "Movie_Name_EN    212506 non-null object\n",
      "Movie_Name_CN    212506 non-null object\n",
      "Crawl_Date       212506 non-null object\n",
      "Number           212506 non-null int64\n",
      "Username         212496 non-null object\n",
      "Date             212506 non-null object\n",
      "Star             212506 non-null int64\n",
      "Comment          212506 non-null object\n",
      "Like             212506 non-null int64\n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 16.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#输出数据的一些相关信息\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>连奥创都知道整容要去韩国。</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“一个没有黑暗面的人不值得信任。” 第二部剥去冗长的铺垫，开场即高潮、一直到结束，会有人觉...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>奥创弱爆了弱爆了弱爆了啊！！！！！！</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>与第一集不同，承上启下，阴郁严肃，但也不会不好看啊，除非本来就不喜欢漫威电影。场面更加宏大...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>看毕，我激动地对友人说，等等奥创要来毁灭台北怎么办厚，她拍了拍我肩膀，没事，反正你买了两份...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Star\n",
       "0                                      连奥创都知道整容要去韩国。     3\n",
       "1   “一个没有黑暗面的人不值得信任。” 第二部剥去冗长的铺垫，开场即高潮、一直到结束，会有人觉...     4\n",
       "2                                 奥创弱爆了弱爆了弱爆了啊！！！！！！     2\n",
       "3   与第一集不同，承上启下，阴郁严肃，但也不会不好看啊，除非本来就不喜欢漫威电影。场面更加宏大...     4\n",
       "4   看毕，我激动地对友人说，等等奥创要来毁灭台北怎么办厚，她拍了拍我肩膀，没事，反正你买了两份...     5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#只保留数据中我们需要的两列：Comment列和Star列\n",
    "data = data[['Comment','Star']]\n",
    "#观察新的数据的格式\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>连奥创都知道整容要去韩国。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“一个没有黑暗面的人不值得信任。” 第二部剥去冗长的铺垫，开场即高潮、一直到结束，会有人觉...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>奥创弱爆了弱爆了弱爆了啊！！！！！！</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>与第一集不同，承上启下，阴郁严肃，但也不会不好看啊，除非本来就不喜欢漫威电影。场面更加宏大...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>看毕，我激动地对友人说，等等奥创要来毁灭台北怎么办厚，她拍了拍我肩膀，没事，反正你买了两份...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Star\n",
       "0                                      连奥创都知道整容要去韩国。     1\n",
       "1   “一个没有黑暗面的人不值得信任。” 第二部剥去冗长的铺垫，开场即高潮、一直到结束，会有人觉...     1\n",
       "2                                 奥创弱爆了弱爆了弱爆了啊！！！！！！     0\n",
       "3   与第一集不同，承上启下，阴郁严肃，但也不会不好看啊，除非本来就不喜欢漫威电影。场面更加宏大...     1\n",
       "4   看毕，我激动地对友人说，等等奥创要来毁灭台北怎么办厚，她拍了拍我肩膀，没事，反正你买了两份...     1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这里的star代表具体的评分。但在这个项目中，我们要预测的是正面还是负面。我们把评分为1和2的看作是负面，把评分为3，4，5的作为正面\n",
    "data['Star']=(data.Star/3).astype(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务1： 去掉一些无用的字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO1: 去掉一些无用的字符，自行定一个字符几何，并从文本中去掉\n",
    "#    your to do \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务2：使用结巴分词对文本做分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "apply: 100%|██████████| 212506/212506 [00:00<00:00, 1005813.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# TODO2: 导入中文分词包jieba, 并用jieba对原始文本做分词\n",
    "import jieba\n",
    "def comment_cut(content):\n",
    "    # TODO: 使用结巴完成对每一个comment的分词\n",
    "    pass\n",
    "\n",
    "# 输出进度条\n",
    "tqdm.pandas(desc='apply')\n",
    "data['comment_processed'] = data['Comment'].progress_apply(comment_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Star</th>\n",
       "      <th>comment_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>连奥创都知道整容要去韩国。</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“一个没有黑暗面的人不值得信任。” 第二部剥去冗长的铺垫，开场即高潮、一直到结束，会有人觉...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>奥创弱爆了弱爆了弱爆了啊！！！！！！</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>与第一集不同，承上启下，阴郁严肃，但也不会不好看啊，除非本来就不喜欢漫威电影。场面更加宏大...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>看毕，我激动地对友人说，等等奥创要来毁灭台北怎么办厚，她拍了拍我肩膀，没事，反正你买了两份...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Star comment_processed\n",
       "0                                      连奥创都知道整容要去韩国。     0              None\n",
       "1   “一个没有黑暗面的人不值得信任。” 第二部剥去冗长的铺垫，开场即高潮、一直到结束，会有人觉...     0              None\n",
       "2                                 奥创弱爆了弱爆了弱爆了啊！！！！！！     0              None\n",
       "3   与第一集不同，承上启下，阴郁严肃，但也不会不好看啊，除非本来就不喜欢漫威电影。场面更加宏大...     0              None\n",
       "4   看毕，我激动地对友人说，等等奥创要来毁灭台北怎么办厚，她拍了拍我肩膀，没事，反正你买了两份...     0              None"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 观察新的数据的格式\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务3：设定停用词并去掉停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-14-bb189d611c89>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-bb189d611c89>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    data['comment_processed'] = data['comment_processed'].progress_apply(rm_stop_word)\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# TODO3: 设定停用词并从文本中去掉停用词\n",
    "\n",
    "# 下载中文停用词表至data/stopWord.json中，下载地址:https://github.com/goto456/stopwords/\n",
    "if not os.path.exists('data/stopWord.json'):\n",
    "    stopWord = requests.get(\"https://raw.githubusercontent.com/goto456/stopwords/master/cn_stopwords.txt\")\n",
    "    with open(\"data/stopWord.json\", \"wb\") as f:\n",
    "         f.write(stopWord.content)\n",
    "\n",
    "# 读取下载的停用词表，并保存在列表中\n",
    "with open(\"data/stopWord.json\",\"r\") as f:\n",
    "    stopWords = f.read().split(\"\\n\")  \n",
    "    \n",
    "    \n",
    "# 去除停用词\n",
    "def rm_stop_word(wordList):\n",
    "    # your code, remove stop words\n",
    "    # TODO\n",
    "\n",
    "#这行代码中.progress_apply()函数的作用等同于.apply()函数的作用，只是写成.progress_apply()函数才能被tqdm包监控从而输出进度条。\n",
    "data['comment_processed'] = data['comment_processed'].progress_apply(rm_stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 观察新的数据的格式\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务4：去掉低频词，出现次数少于10次的词去掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO4: 去除低频词, 去掉词频小于10的单词，并把结果存放在data['comment_processed']里\n",
    "\n",
    "\n",
    "data['comment_processed'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 把文本分为训练集和测试集\n",
    "选择语料库中的20%作为测试数据，剩下的作为训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO5: 把数据分为训练集和测试集. comments_train（list)保存用于训练的文本，comments_test(list)保存用于测试的文本。 y_train, y_test是对应的标签（0、1）\n",
    "\n",
    "test_ratio = 0.2\n",
    "comments_train, comments_test = \n",
    "y_train, y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 把文本转换成向量的形式\n",
    "\n",
    "在这个部分我们会采用三种不同的方式:\n",
    "- 使用tf-idf向量\n",
    "- 使用word2vec\n",
    "- 使用bert向量\n",
    "\n",
    "转换成向量之后，我们接着做模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务6：把文本转换成tf-idf向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-a3db87312644>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-a3db87312644>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    tfidf_train=\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# TODO6: 把训练文本和测试文本转换成tf-idf向量。使用sklearn的feature_extraction.text.TfidfTransformer模块\n",
    "#    请留意fit_transform和transform之间的区别。 常见的错误是在训练集和测试集上都使用 fit_transform，需要避免！ \n",
    "#    另外，可以留意一下结果是否为稀疏矩阵\n",
    "\n",
    "tfidf_train=\n",
    "tfidf_test=\n",
    "print (tfidf_train.shape, tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务7：把文本转换成word2vec向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于训练出一个高效的word2vec词向量往往需要非常大的语料库与计算资源，所以我们通常不自己训练Wordvec词向量，而直接使用网上开源的已训练好的词向量。\n",
    "# data/sgns.zhihu.word是从https://github.com/Embedding/Chinese-Word-Vectors下载到的预训练好的中文词向量文件\n",
    "# 使用KeyedVectors.load_word2vec_format()函数加载预训练好的词向量文件\n",
    "model = KeyedVectors.load_word2vec_format('data/sgns.zhihu.word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#预训练词向量使用举例\n",
    "model['今天']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO7: 对于每个句子，生成句子的向量。具体的做法是：包含在句子中的所有单词的向量做平均。\n",
    "vocabulary = model.vocab\n",
    "\n",
    "word2vec_train=\n",
    "word2vec_test=\n",
    "print (word2vec_train.shape, word2vec_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务8：把文本转换成bert向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-42afd78e0bdb>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-42afd78e0bdb>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    bert_train=\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 导入gpu版本的bert embedding预训练的模型。\n",
    "# 若没有gpu，则ctx可使用其默认值cpu(0)。但使用cpu会使程序运行的时间变得非常慢\n",
    "# 若之前没有下载过bert embedding预训练的模型，执行此句时会花费一些时间来下载预训练的模型\n",
    "ctx = mxnet.gpu()\n",
    "embedding = BertEmbedding(ctx=ctx)\n",
    "\n",
    "# TODO8: 跟word2vec一样，计算出训练文本和测试文本的向量，仍然采用单词向量的平均。\n",
    "bert_train=\n",
    "bert_test=\n",
    "print (bert_train.shape, bert_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (tfidf_train.shape, tfidf_test.shape)\n",
    "print (word2vec_train.shape, word2vec_test.shape)\n",
    "print (bert_train.shape, bert_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 训练模型以及评估\n",
    "对如上三种不同的向量表示法，分别训练逻辑回归模型，需要做：\n",
    "- 搭建模型\n",
    "- 训练模型（并做交叉验证）\n",
    "- 输出最好的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入逻辑回归的包\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务9：使用tf-idf，并结合逻辑回归训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO9: 使用tf-idf + 逻辑回归训练模型，需要用gridsearchCV做交叉验证，并选择最好的超参数\n",
    "\n",
    "\n",
    "\n",
    "print('TF-IDF LR test accuracy %s' % metrics.accuracy_score(y_test, tf_idf_y_pred))\n",
    "#逻辑回归模型在测试集上的F1_Score\n",
    "print('TF-IDF LR test F1_score %s' % metrics.f1_score(y_test, tf_idf_y_pred,average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务10：使用word2vec，并结合逻辑回归训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO10: 使用word2vec + 逻辑回归训练模型，需要用gridsearchCV做交叉验证，并选择最好的超参数\n",
    "\n",
    "\n",
    "\n",
    "print('Word2vec LR test accuracy %s' % metrics.accuracy_score(y_test, word2vec_y_pred))\n",
    "#逻辑回归模型在测试集上的F1_Score\n",
    "print('Word2vec LR test F1_score %s' % metrics.f1_score(y_test, word2vec_y_pred,average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务11：使用bert，并结合逻辑回归训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO11: 使用bert + 逻辑回归训练模型，需要用gridsearchCV做交叉验证，并选择最好的超参数\n",
    "\n",
    "\n",
    "\n",
    "print('Bert LR test accuracy %s' % metrics.accuracy_score(y_test, bert_y_pred))\n",
    "#逻辑回归模型在测试集上的F1_Score\n",
    "print('Bert LR test F1_score %s' % metrics.f1_score(y_test, bert_y_pred,average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务12：对于以上结果请做一下简单的总结，按照1，2，3，4提取几个关键点，包括：\n",
    "- 结果说明什么问题？\n",
    "- 接下来如何提高？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "2.\n",
    "3.\n",
    "4.\n",
    "5.\n",
    "6."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
